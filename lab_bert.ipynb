{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGgu-NtjXZPP"
   },
   "source": [
    "# Практическое задание 3 \n",
    "\n",
    "# Классификация предложений с использованием BERT\n",
    "\n",
    "## курс \"Математические методы анализа текстов\"\n",
    "\n",
    "\n",
    "### ФИО: Садиев Абдурахмон Абдужалолович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GczH03BxXZPR"
   },
   "source": [
    "## Введение\n",
    "\n",
    "### Постановка задачи\n",
    "\n",
    "В этом задании вы будете классифицировать предложения из медицинских статей на несколько классов (background, objective и т.д.). \n",
    "Для того, чтобы улучшить качество решения вам предлагается дообучить предобученную нейросетевую архитектуру BERT.\n",
    "\n",
    "### Библиотеки\n",
    "\n",
    "Для этого задания вам понадобятся следующие библиотеки:\n",
    " - [Pytorch](https://pytorch.org/).\n",
    " - [Transformers](https://github.com/huggingface/transformers).\n",
    " \n",
    "### Данные\n",
    "\n",
    "Скачать данные можно здесь: [ссылка на google диск](https://drive.google.com/file/d/13HlWH8jnmsxqDKrEptxOXQg9kkuQMmGq/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "luRDXxlIXZPU"
   },
   "source": [
    "## Часть 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bGNAEqV0XZPV"
   },
   "source": [
    "Мы будем работать с предложениями из медицинских статей, разбитых на несколько классов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8eEFXiJXZPX"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_w2lpTW6XZPb"
   },
   "source": [
    "Путь к папке с данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hUN30XGzYn-q",
    "outputId": "181413a4-c34c-4b4a-b67c-6a9e47e0bd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "from google.colab import drive, files\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5kXhbssXZPc"
   },
   "outputs": [],
   "source": [
    "#colab\n",
    "DATA_PATH = \"/content/gdrive/My Drive/Bert/sentence_classification_data\"\n",
    "# DATA_PATH = \"sentence_classification_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tK5XZPBFXZPg"
   },
   "source": [
    "Функция считывания данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mqo2-oRXZPg"
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        Pubmed sentences file path\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    text_data : list of str\n",
    "        List of sentences for algorithm\n",
    "    \n",
    "    target_data : list of str\n",
    "        List of sentence categories\n",
    "    \"\"\"\n",
    "    text_data = []\n",
    "    target_data = []\n",
    "\n",
    "    with open(file_name, 'r') as f_input:\n",
    "        for line in f_input:\n",
    "            if line.startswith('#') or line == '\\n':\n",
    "                continue\n",
    "            target, text = line.split('\\t')[:2]    \n",
    "\n",
    "            text_data.append(text)\n",
    "            target_data.append(target)\n",
    "    \n",
    "    return text_data, target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eP9AGo8mXZPu"
   },
   "source": [
    "Считывание данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GbaemlvXZPz"
   },
   "outputs": [],
   "source": [
    "train_data, train_target = read_data(f'{DATA_PATH}/data_train.txt')\n",
    "test_data, test_target = read_data(f'{DATA_PATH}/data_test.txt')\n",
    "dev_data, dev_target = read_data(f'{DATA_PATH}/data_dev.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lx8XRs7nXZP2"
   },
   "source": [
    "\n",
    "## Часть 2. Построение бейзлайна (1 балл)\n",
    "\n",
    "В этой части задания вам необходимо построить бейзлайн модель, с которой вы будете сравнивать ваше решение. В качестве бейзлайна вам предлагается использовать модель логистической регрессии на tf-idf представлениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waDd8NjkXZP3"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVjmLCoTXZP4"
   },
   "source": [
    "Перед тем как подать в модель предложения, необходимо их предобработать:\n",
    "    \n",
    "1. привести все предложения к нижнему регистру\n",
    "2. удалить из предложений все непробельные символы кроме букв, цифр\n",
    "3. все цифры заменить на нули\n",
    "\n",
    "Метки ответов необходимо преобразовать из текстового вида в числовой (это можно сделать с помощью LabelEncoder).\n",
    "\n",
    "Затем необходимо построить tf-idf матрицу по выбранным предложениям (используйте для подсчёта tf-idf только train_data!) и обучить на них модель логистической регрессии. Используйте dev выборку для подбора гиперпараметров модели. Добейтесь того, что на test и dev выборках accuracy будет будет выше 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VPzdOKATXZP4",
    "outputId": "e5ac9682-5e2b-4c75-e9ec-37938258c5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plasma samples were obtained and analysed with timeresolved immunofluorometric assays determining the plasma levels of map44  masp1  and masp3 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Plasma samples were obtained and analysed with time-resolved immunofluorometric assays determining the plasma levels of MAp44 , MASP-1 , and MASP-3 .\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(re.sub(r'[^a-zA-Z0-9\\s]', '', train_data[5]).lower().replace('\\n', ''))\n",
    "\n",
    "train_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQ7bgF94XZP6"
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data_preprocessed = []\n",
    "    for sentence in data:\n",
    "        sentence = re.sub(r'[^a-zA-Z0-9\\s]', '', sentence).lower().replace('\\n', '')\n",
    "        sentence = re.sub(r'([0-9])', r'0',sentence)\n",
    "        data_preprocessed.append(sentence)\n",
    "    return data_preprocessed\n",
    "LE = LabelEncoder()\n",
    "\n",
    "train_data_preprocessed = preprocess(train_data)\n",
    "y_train = LE.fit_transform(train_target)\n",
    "\n",
    "test_data_preprocessed = preprocess(test_data)\n",
    "y_test = LE.transform(test_target)\n",
    "\n",
    "dev_data_preprocessed = preprocess(dev_data)\n",
    "y_dev = LE.transform(dev_target)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1, 3))\n",
    "X_train = vectorizer.fit_transform(train_data_preprocessed)\n",
    "X_test = vectorizer.transform(test_data_preprocessed)\n",
    "X_dev = vectorizer.transform(dev_data_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "IAnd8nRKbQ0j",
    "outputId": "2f2b3a10-4977-4676-9f73-04b3d0c10fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) C: 1.0,  Accuracy: 0.7960735517765796\n",
      "\n",
      "(2) C: 1.9477340410546757,  Accuracy: 0.8045416839485691\n",
      "\n",
      "(3) C: 3.7936678946831774,  Accuracy: 0.8087239043273884\n",
      "\n",
      "(4) C: 7.38905609893065,  Accuracy: 0.8098645098852482\n",
      "\n",
      "(5) C: 14.391916095149892,  Accuracy: 0.810348403152219\n",
      "\n",
      "(6) C: 28.031624894526125,  Accuracy: 0.8103138393474354\n",
      "\n",
      "(7) C: 54.598150033144236,  Accuracy: 0.8097608184708973\n",
      "\n",
      "(8) C: 106.34267539816545,  Accuracy: 0.8100373289091664\n",
      "\n",
      "(9) C: 207.1272488898345,  Accuracy: 0.8100373289091664\n",
      "\n",
      "(10) C: 403.4287934927351,  Accuracy: 0.8098299460804645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "acc_dev =[]\n",
    "for i, C_reg in enumerate(np.exp(np.linspace(0,6,10))):\n",
    "    clf = LogisticRegression(penalty = 'l2', \n",
    "                              C = C_reg, \n",
    "                              solver = 'newton-cg', \n",
    "                              multi_class = 'multinomial', \n",
    "                              max_iter = 1000)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_dev)\n",
    "    acc = accuracy_score(y_predict, y_dev)\n",
    "    acc_dev.append(acc)\n",
    "    print('({0}) C: {1},  Accuracy: {2}\\n'.format(i+1, C_reg, acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hmNIu5GZ385B",
    "outputId": "b9156dc3-b380-48ff-d06a-72200c530c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8082572356313081\n",
      "dev accuracy: 0.810348403152219\n"
     ]
    }
   ],
   "source": [
    "ind = acc_dev.index(max(acc_dev))\n",
    "clf = LogisticRegression(penalty = 'l2', \n",
    "                         C = np.exp(np.linspace(0,6,10))[ind], \n",
    "                         solver = 'newton-cg', \n",
    "                         multi_class = 'multinomial', \n",
    "                         max_iter = 1000)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('test accuracy: {}'.format(accuracy_score(clf.predict(X_test), y_test)))\n",
    "print('dev accuracy: {}'.format(accuracy_score(clf.predict(X_dev), y_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSfGeCjzXZP9"
   },
   "source": [
    "## Часть 3. Задание BERT (4 балла за 3 и 4 части)\n",
    "\n",
    "Так как обучающих предложений очень мало, попробуем использовать модель BERT, предобученную на большом датасете. Будем использовать библиотеку transformers. Для обучения модели используйте данные до обработки из предыдущего пункта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qByLzYY1XZP-"
   },
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "NUM_LABELS = len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "-lMPjVhn8pxP",
    "outputId": "62fa826d-cecf-4383-a1ff-995f1ef6f169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.14)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.11.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.14)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers #colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "lVPr0PSXXZQC",
    "outputId": "c2dd53b1-439a-4eea-a1ab-660fcf8c23e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ctMVugPXZQE"
   },
   "source": [
    "Модель BERT работает с специальным форматом данных — все токены из предложения получены с помощью алгоритма BPE. Класс BertTokenizer позволяет получить BPE разбиение для предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HA75pO5ZXZQE"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qlvfNdx-XZQG"
   },
   "source": [
    "В библиотеке transformers есть специальный класс для работы с задачей классификации — BertForSequenceClassification. Воспользуемся им, чтобы задать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PGK8xddtXZQH",
    "outputId": "39672318-09dc-40b8-a018-3f8893a988fd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = BertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL_NAME, num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "bert_model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTcu-ifnXZQI"
   },
   "source": [
    "Реализуем специальный кастомный датасет для токенизированных с помощью BPE предложений. Каждое предложение должно быть преобразовано в последовательность BPE индексов. Не забудьте, что в начале каждого предложения должен стоять специальный токен [CLS], а в конце должен стоять специальный токен [SEP].\n",
    "\n",
    "Задайте датасет, используя BertTokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbTpTNx2XZQI"
   },
   "outputs": [],
   "source": [
    "class BertTokenizedDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text_data, target_data=None, max_length=256):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokenizer : instance of BertTokenizer\n",
    "        text_data : list of str\n",
    "            List of input sentences\n",
    "        target_data : list of int\n",
    "            List of input targets\n",
    "        max_length : int\n",
    "            Maximum length of input sequence (length in bpe tokens)\n",
    "        \"\"\"\n",
    "        super(BertTokenizedDataset, self).__init__()\n",
    "        self.data = []\n",
    "        self.target_data = target_data\n",
    "\n",
    "        for sentence in text_data:\n",
    "            tokens = tokenizer.encode('[CLS] ' + sentence + ' [SEP]', max_length=max_length)\n",
    "            tokens = torch.LongTensor(tokens)\n",
    "            self.data.append(tokens)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if self.target_data is not None:\n",
    "            return self.data[i], self.target_data[i]\n",
    "        else:\n",
    "            return self.data[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VZIqJMNiXZQK"
   },
   "source": [
    "Получите все датасеты для всех типов данных. \n",
    "\n",
    "**Замечание**. После получения есть смысл сохранить все датасеты на диск, т.к. предобработка занимает время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6gXLtbzXZQK"
   },
   "outputs": [],
   "source": [
    "train_dataset = BertTokenizedDataset(tokenizer, train_data, y_train)\n",
    "dev_dataset = BertTokenizedDataset(tokenizer, dev_data, y_dev)\n",
    "test_dataset = BertTokenizedDataset(tokenizer, test_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "GpgGvzbik-7c",
    "outputId": "c443e71f-ac6e-46e3-f64f-49fcd4bea1be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101, 12123,  8168,  2020,  4663,  1998, 20302, 23274,  2094,  2007,\n",
       "         2051,  1011, 10395, 10047, 23041, 11253,  7630, 14604, 12589,  4632,\n",
       "        22916, 12515,  1996, 12123,  3798,  1997,  4949, 22932,  1010, 16137,\n",
       "         2361,  1011,  1015,  1010,  1998, 16137,  2361,  1011,  1017,  1012,\n",
       "          102])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZvOrOzZXZQM"
   },
   "source": [
    "Используем  класс PadSequences, чтобы задать способ паддинга, работающий с встроенным в pytorch DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k49refzgXZQM"
   },
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, use_labels=False):\n",
    "        self.use_labels = use_labels\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : list of objects or list of (object, label)\n",
    "            Each object is list of int indexes.\n",
    "            Each label is int.\n",
    "        \"\"\"\n",
    "        data_label_batch = batch if self.use_labels else [(x, 0) for x in batch]\n",
    "            \n",
    "        # Sort the batch in the descending order\n",
    "        sorted_batch = sorted(data_label_batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "        # Get each sequence and pad it\n",
    "        sequences = [x[0] for x in sorted_batch]\n",
    "        sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "        max_lenght = len(sequences[0])\n",
    "\n",
    "        # Also need to store the length of each sequence\n",
    "        # This is later needed in order to unpad the sequences\n",
    "        lengths = torch.LongTensor([[1] * len(x) + [0] * (max_lenght - len(x)) for x in sequences])\n",
    "        # Don't forget to grab the labels of the *sorted* batch\n",
    "        \n",
    "        if self.use_labels:\n",
    "            labels = torch.LongTensor([x[1] for x in sorted_batch])\n",
    "            return sequences_padded, lengths, labels\n",
    "        else:\n",
    "            return sequences_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3s-aW_nXZQN"
   },
   "source": [
    "Зададим DataLoader для каждого из датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKaykmtFXZQN"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "md5L9lmJXZQO"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              collate_fn=PadSequences(use_labels=True))\n",
    "\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                              collate_fn=PadSequences(use_labels=True))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                              collate_fn=PadSequences(use_labels=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHQhvlP8XZQP"
   },
   "source": [
    "Заметьте, что модель трансформера обучается по достаточному большому размеру батча (обычно 64), который скорее всего не будет влезать на вашу видеокарту. Поэтому, рекомендуется \"накапливать\" градиенты за несколько итераций. С помощью параметра ACCUMULATION_STEPS задайте, раз в сколько итераций вам необходимо делать шаг метода оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebnPIX_yXZQP"
   },
   "outputs": [],
   "source": [
    "EPOCH_AMOUNT = 2\n",
    "TRAIN_LENGTH = len(train_dataset)\n",
    "BATCH_SIZE = 16\n",
    "ACCUMULATION_STEPS = 4\n",
    "\n",
    "LR = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44NyOjPQXZQQ"
   },
   "source": [
    "Посчитайте общее число раз, когда ваш оптимизатор будет делать обновления на основе выбранных значений EPOCH_AMOUNT, BATCH_SIZE, ACCUMULATION_STEPS и  TRAIN_LENGTH. Эта величина нужна для правильного задания параметров оптимизаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lDg3lJYVXZQQ",
    "outputId": "f904da62-1922-4975-9541-72051fc343c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_optimization_step_amount = 921.65625 \n",
      "train_optimization_step_amount we use = 920 \n"
     ]
    }
   ],
   "source": [
    "train_optimization_step_amount_float = EPOCH_AMOUNT * (TRAIN_LENGTH / (BATCH_SIZE * ACCUMULATION_STEPS ))\n",
    "train_optimization_step_amount = EPOCH_AMOUNT * int(TRAIN_LENGTH / (BATCH_SIZE * ACCUMULATION_STEPS ))\n",
    "print('train_optimization_step_amount = {} '.format(train_optimization_step_amount_float))\n",
    "print('train_optimization_step_amount we use = {} '.format(train_optimization_step_amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOagAQfHXZQR"
   },
   "source": [
    "Зададим параметры оптимизаторов. Мы будем использовать специальные оптимизаторы из библиотеки transformers AdamW и WarmupLinearSchedule, обеспечивающие плавный разгон и медленное затухание темпа обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQOpiuSlXZQR"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(bert_model.parameters(), lr=LR, correct_bias=False)\n",
    "scheduler = WarmupLinearSchedule(\n",
    "    optimizer,\n",
    "    warmup_steps=train_optimization_step_amount * 0.05,\n",
    "    t_total=train_optimization_step_amount,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jUhqyaYXZQS"
   },
   "source": [
    "Для некоторых групп параметров зададим коэффициенты регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyUUetEhXZQS"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(bert_model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1jIWomBXZQT"
   },
   "source": [
    "## Часть 4. Обучение BERT \n",
    "\n",
    "Теперь всё готово к тому, чтобы дообучить BERT на датасете train_dataset!\n",
    "\n",
    "Используйте dev_dataset для выбора гиперпараметров модели и обучения. Задание будет засчтано на полный балл если на dev_dataset и test_dataset точность будет выше 0.84."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "yki1BoBBsci1",
    "outputId": "89b8b62f-fcd4-4325-a40e-12371068022f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 18 16:57:37 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P0    42W / 250W |   2941MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v3uzm_mtnrKD",
    "outputId": "5e7d12e2-1d03-48cf-fe4d-b8f71cae3130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "uiUcHw77uKm6",
    "outputId": "876027af-8cf7-4e90-99dc-6c51cb806678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch 1/2, Step : 0/920, Loss: 1.6729981899261475 \n",
      "\n",
      "Train: Epoch 1/2, Step : 100/920, Loss: 0.4701715111732483 \n",
      "\n",
      "Train: Epoch 1/2, Step : 200/920, Loss: 0.7067486643791199 \n",
      "\n",
      "Train: Epoch 1/2, Step : 300/920, Loss: 0.7015130519866943 \n",
      "\n",
      "Train: Epoch 1/2, Step : 400/920, Loss: 0.2623586654663086 \n",
      "\n",
      "Dev accuracy: 0.8609038142620232\n",
      "Train: Epoch 2/2, Step : 461/920, Loss: 0.6440114974975586 \n",
      "\n",
      "Train: Epoch 2/2, Step : 561/920, Loss: 0.4651113748550415 \n",
      "\n",
      "Train: Epoch 2/2, Step : 661/920, Loss: 0.29276227951049805 \n",
      "\n",
      "Train: Epoch 2/2, Step : 761/920, Loss: 0.11788536608219147 \n",
      "\n",
      "Train: Epoch 2/2, Step : 861/920, Loss: 0.41912785172462463 \n",
      "\n",
      "Dev accuracy: 0.8648770038695411\n"
     ]
    }
   ],
   "source": [
    "bert_model.train()\n",
    "step = 0\n",
    "\n",
    "for epoch in range(EPOCH_AMOUNT):\n",
    "    for iteration, batch in enumerate(train_dataloader):\n",
    "        input_ids, labels_ids = batch[0], batch[2]\n",
    "        outputs = bert_model(input_ids.to(device), labels=labels_ids.to(device))\n",
    "        loss, predict = outputs\n",
    "        loss.backward()\n",
    "\n",
    "        if (iteration + 1) % ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            step += 1\n",
    "        if iteration % 400 == 0:\n",
    "            print('Train: Epoch {0}/{1}, Step : {2}/{3}, Loss: {4} \\n'.format(epoch + 1, EPOCH_AMOUNT, step, train_optimization_step_amount, loss))\n",
    "        \n",
    "      \n",
    "    bert_model.eval()\n",
    "    num_steps = 0\n",
    "    ratio_right_ans_dev = 0\n",
    "\n",
    "    for batch in dev_dataloader:\n",
    "        input_ids, labels_ids = batch[0], batch[2]\n",
    "        input_ids, labels_ids = input_ids.to(device), labels_ids.to(device)\n",
    "        labels_ids = labels_ids.to('cpu').numpy()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = bert_model(input_ids)  \n",
    "        predict = predict[0].to('cpu').numpy()\n",
    "        predict = np.argmax(predict, axis=1)\n",
    "\n",
    "        ratio_right_ans_dev += np.sum(predict == labels_ids)/ len(labels_ids)\n",
    "        num_steps += 1\n",
    "\n",
    "    print('Dev accuracy: {}'.format(ratio_right_ans_dev /  num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uBgLs0AJ1fiz",
    "outputId": "048d13ab-e4c0-4cbe-d12c-4fb2c62b816f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8613266597899475\n"
     ]
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "test_num_steps = 0\n",
    "ratio_right_ans_test = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    input_ids, labels_ids = batch[0], batch[2]\n",
    "    input_ids, labels_ids = input_ids.to(device), labels_ids.to(device)\n",
    "    labels_ids = labels_ids.detach().to('cpu').numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predict = bert_model(input_ids)  \n",
    "    predict = predict[0].to('cpu').numpy()\n",
    "    predict = np.argmax(predict, axis=1)\n",
    "    \n",
    "    ratio_right_ans_test += np.sum(predict == labels_ids) / len(labels_ids)\n",
    "    test_num_steps += 1\n",
    "\n",
    "print('Test accuracy: {}'.format(ratio_right_ans_test /  test_num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "SkrhqeBQ4uwc",
    "outputId": "e71a6841-269e-4294-defb-c7077ca88dd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev accuracy: 0.8648770038695411\n",
      "Test accuracy: 0.8613266597899475\n"
     ]
    }
   ],
   "source": [
    "print('Dev accuracy: {}'.format(ratio_right_ans_dev /  num_steps))\n",
    "print('Test accuracy: {}'.format(ratio_right_ans_test /  test_num_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajHnaxyIXZQY"
   },
   "source": [
    "## Бонусная часть (до 3 баллов)\n",
    "\n",
    "Улучшите качество (на обеих выборках), используя любые способы (кроме использования дополнительных обучающих данных датасета RCT2000):\n",
    "\n",
    "* $> 0.86$ — 1 балл \n",
    "* $> 0.88$ — 2 балла\n",
    "* $> 0.9$ — 3 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "V31r_MAv6PrB",
    "outputId": "6347f76a-6963-472a-8a83-c42231d5c858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev accuracy: 0.8648770038695411\n",
      "Test accuracy: 0.8613266597899475\n"
     ]
    }
   ],
   "source": [
    "print('Dev accuracy: {}'.format(ratio_right_ans_dev /  num_steps))\n",
    "print('Test accuracy: {}'.format(ratio_right_ans_test /  test_num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXZVLHZu6STP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab_bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
